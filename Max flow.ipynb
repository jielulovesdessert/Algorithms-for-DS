{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie distribution\n",
    "\n",
    "\n",
    "The dataset contiguous-usa.dat lists the adjacent states in the US. Each line lists two adjacent states; thus AK and HI are omitted, but DC is included in the data. The following code reads in the graph of US states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = nx.Graph()\n",
    "\n",
    "usa = open('contiguous-usa.dat')\n",
    "for line in usa:\n",
    "    s1, s2 = line.strip().split()\n",
    "    G.add_edge(s1, s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now encode the demands into the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for state in G.nodes():\n",
    "    if state != 'CA':\n",
    "        G.node[state]['demand'] = 1\n",
    "G.node['CA']['demand'] = -48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will assign a uniform capacity of 16 to each edge. Since CA has only three adjacent states, this is the smallest possible uniform capacity that allows one to ship all 48 units out of CA. As we have created an undirected graph, and flows have directions, we first convert the graph to a directed graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = nx.DiGraph(G)\n",
    "uniform_capacity = 16\n",
    "for (s1, s2) in G.edges():\n",
    "    G.edge[s1][s2]['capacity'] = uniform_capacity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flow_with_demands(graph):\n",
    "    \"\"\"Computes a flow with demands over the given graph.\n",
    "    \n",
    "    Args:\n",
    "        graph: A directed graph with nodes annotated with 'demand' properties and edges annotated with 'capacity' \n",
    "            properties.\n",
    "        \n",
    "    Returns:\n",
    "        A dict of dicts containing the flow on each edge. For instance, flow[s1][s2] should provide the flow along\n",
    "        edge (s1, s2).\n",
    "        \n",
    "    Raises:\n",
    "        NetworkXUnfeasible: An error is thrown if there is no flow satisfying the demands.\n",
    "    \"\"\"\n",
    "    # TODO: Implement the function.\n",
    "    def start_check(graph):\n",
    "        demand = 0\n",
    "        for state in graph.nodes():\n",
    "            demand += graph.node[state]['demand']\n",
    "        if demand != 0:\n",
    "            raise nx.NetworkXUnfeasible(\"An error is thrown if there is no flow satisfying the demands.\")\n",
    "        return\n",
    "    \n",
    "    def build_super(G):\n",
    "        G.add_node('S')\n",
    "        G.add_node('T')\n",
    "        for state in G.nodes():\n",
    "            if state != 'S'and state != 'T':\n",
    "                if G.node[state]['demand'] < 0:\n",
    "                    G.add_edge('S', state)\n",
    "                    G.edge['S'][state]['capacity'] = -G.node[state]['demand']\n",
    "                if G.node[state]['demand'] > 0:\n",
    "                    G.add_edge(state, 'T')\n",
    "                    G.edge[state]['T']['capacity'] = G.node[state]['demand']\n",
    "        return G\n",
    "    \n",
    "    def reset(G):\n",
    "        keys, values = [], []\n",
    "        for v in G.nodes():\n",
    "            keys.append(v)\n",
    "            res = dict()\n",
    "            for (v1, v2) in G.edges():\n",
    "                if v1 == v:\n",
    "                    res[v2] = 0\n",
    "            values.append(res)\n",
    "        flow = dict()\n",
    "        for i, j in enumerate(keys):\n",
    "            flow[j] = values[i]\n",
    "        return flow\n",
    "\n",
    "    def residual(G, flow):\n",
    "        G_r = nx.DiGraph()\n",
    "        for (s1, s2) in G.edges():\n",
    "            if flow[s1][s2] > 0:\n",
    "                G_r.add_edge(s2, s1)\n",
    "                G_r[s2][s1]['capacity'] = flow[s1][s2]\n",
    "            if flow[s1][s2] < G[s1][s2]['capacity']:\n",
    "                G_r.add_edge(s1, s2)\n",
    "                G_r[s1][s2]['capacity'] = G[s1][s2]['capacity'] - flow[s1][s2]\n",
    "        return G_r\n",
    "\n",
    "    def bfs(G, node):\n",
    "        queue,discovered,prev = [node],[node],{}\n",
    "        while len(queue) > 0:\n",
    "            u = queue[0]\n",
    "            queue = queue[1:]\n",
    "            for v in G.neighbors(u):\n",
    "                if v not in discovered:\n",
    "                    prev[v] = u\n",
    "                    discovered.append(v)\n",
    "                    queue.append(v)\n",
    "        return [prev, discovered]\n",
    "\n",
    "    def Path_Helper(G, s, t):\n",
    "        prev, discovered = bfs(G, s)\n",
    "        if t in discovered:\n",
    "            path = [t]\n",
    "            key = t\n",
    "            while key != None:          \n",
    "                if key in prev.keys():\n",
    "                    path.append(prev[key])\n",
    "                    key = prev[key]\n",
    "                else: \n",
    "                    key = None\n",
    "            return path[::-1]\n",
    "        else:\n",
    "            return None\n",
    "            \n",
    "    def Augmenting_Path(G, path, G_r, flow):\n",
    "        capacities = []\n",
    "        for i in range(len(path)-1):\n",
    "            s1 = path[i]\n",
    "            s2 = path[i+1]\n",
    "            capacities.append(G_r.edge[s1][s2]['capacity'])\n",
    "        addition = min(capacities)\n",
    "        for i in range(len(path)-1):\n",
    "            s1 = path[i]\n",
    "            s2 = path[i+1]\n",
    "            if (s1, s2) in G.edges():\n",
    "                flow[s1][s2] = flow[s1][s2] + addition\n",
    "            else:\n",
    "                flow[s2][s1] = flow[s2][s1] - addition\n",
    "        return flow\n",
    "    \n",
    "    def delete_super(flow):     \n",
    "        for key in flow.keys():\n",
    "            if 'S' in flow[key].keys():\n",
    "                del flow[key]['S']\n",
    "            if 'T' in flow[key].keys():\n",
    "                del flow[key]['T']\n",
    "        del flow['S']\n",
    "        del flow['T']\n",
    "        return flow\n",
    "    \n",
    "    def final_check(G):\n",
    "        max_flow,demand = 0, 0\n",
    "        for (s1, s2) in G.edges():\n",
    "            if s1 == 'S':\n",
    "                max_flow += flow['S'][s2]  \n",
    "        for state in G.nodes():\n",
    "            if state != 'S' and state != 'T':\n",
    "                if G.node[state]['demand'] > 0:\n",
    "                    demand += G.node[state]['demand']      \n",
    "        if max_flow != demand:\n",
    "            raise nx.NetworkXUnfeasible(\"An error is thrown if there is no flow satisfying the demands.\")\n",
    "        return  \n",
    "        \n",
    "    start_check(graph)\n",
    "    G = build_super(graph.copy())\n",
    "    flow = reset(G)\n",
    "    G_r = residual(G, flow)\n",
    "    path = Path_Helper(G_r, 'S', 'T') \n",
    "    while path:\n",
    "        flow = Augmenting_Path(G, path, G_r, flow)\n",
    "        G_r = residual(G, flow)\n",
    "        path = Path_Helper(G_r, 'S', 'T')\n",
    "    final_check(G)\n",
    "    \n",
    "    return delete_super(flow)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a function that computes the total flow into each node (which will be negative for supply nodes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def divergence(flow):\n",
    "    \"\"\"Computes the total flow into each node according to the given flow dict.\n",
    "    \n",
    "    Args:\n",
    "        flow: the flow dict recording flow between nodes.\n",
    "        \n",
    "    Returns:\n",
    "        A dict of the net flow into each node.\n",
    "    \"\"\"\n",
    "    # TODO: Implement the function.\n",
    "    in_flow, out_flow, net_flow = {},{},{}\n",
    "    for i in flow.keys():\n",
    "        in_flow[i],out_flow[i],net_flow[i] = 0,0,0\n",
    "    for v1 in flow.keys():\n",
    "        out_flow[v1] = sum(flow[v1].values())\n",
    "        for v2 in flow[v1].keys():\n",
    "            in_flow[v2] += flow[v1][v2]\n",
    "            \n",
    "    for i in flow.keys():\n",
    "        net_flow[i] = in_flow[i] - out_flow[i]\n",
    "    return net_flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code performs a sanity check my function (but does not completely confirm correctness)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow satisfies all demands: True\n"
     ]
    }
   ],
   "source": [
    "flow = flow_with_demands(G)\n",
    "div = divergence(flow)\n",
    "print \"Flow satisfies all demands:\", all(div[n] == G.node[n]['demand'] for n in G.nodes())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
